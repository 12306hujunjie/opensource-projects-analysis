# L1: åŸºç¡€æ¦‚å¿µä¸å›¾æ„å»º

**å­¦ä¹ ç›®æ ‡**: æŒæ¡LangGraphæ ¸å¿ƒæ¦‚å¿µï¼Œæ„å»ºç¬¬ä¸€ä¸ªå›¾å·¥ä½œæµ  
**é¢„è®¡ç”¨æ—¶**: 2-3å°æ—¶  
**å‰ç½®çŸ¥è¯†**: PythonåŸºç¡€ã€LangChainåŸºæœ¬æ¦‚å¿µ

## ğŸŒŸ æ ¸å¿ƒæ¦‚å¿µç†è§£

### 1.1 ä¸ºä»€ä¹ˆéœ€è¦LangGraphï¼Ÿ

**ä¼ ç»ŸAIå·¥ä½œæµçš„å±€é™æ€§**ï¼š
```python
# ä¼ ç»ŸLangChainé“¾å¼ç»“æ„
from langchain.chains import LLMChain

# çº¿æ€§æ‰§è¡Œï¼ŒçŠ¶æ€ç®¡ç†å¤æ‚
chain = prompt | llm | output_parser
result = chain.invoke({"input": "ç”¨æˆ·è¾“å…¥"})
```

**é—®é¢˜åˆ†æ**ï¼š
- âŒ **çŠ¶æ€å­¤ç«‹**: æ¯ä¸ªç»„ä»¶çš„çŠ¶æ€äº’ä¸ç›¸é€š
- âŒ **å•å‘æµåŠ¨**: åªèƒ½ä»å‰å‘åæ‰§è¡Œï¼Œæ— æ³•å›æº¯æˆ–åˆ†æ”¯
- âŒ **æ‰©å±•å›°éš¾**: æ·»åŠ æ–°é€»è¾‘éœ€è¦é‡æ„æ•´ä¸ªé“¾
- âŒ **é”™è¯¯æ¢å¤**: å¤±è´¥åæ— æ³•ä»ä¸­é—´èŠ‚ç‚¹æ¢å¤

### 1.2 LangGraphçš„é©å‘½æ€§è§£å†³æ–¹æ¡ˆ

**å›¾çŠ¶æ€ç®¡ç†æ¨¡å¼**ï¼š
```python
# LangGraphå›¾çŠ¶æ€ç»“æ„
from langgraph.graph import StateGraph
from typing_extensions import TypedDict

class GraphState(TypedDict):
    messages: list
    current_step: str
    context: dict

# æ¯ä¸ªèŠ‚ç‚¹éƒ½å¯ä»¥è®¿é—®å’Œä¿®æ”¹å…¨å±€çŠ¶æ€
graph = StateGraph(GraphState)
```

**æ ¸å¿ƒä¼˜åŠ¿**ï¼š
- âœ… **çŠ¶æ€å…±äº«**: æ‰€æœ‰èŠ‚ç‚¹å…±äº«ç»Ÿä¸€çš„å…¨å±€çŠ¶æ€
- âœ… **çµæ´»è·¯ç”±**: æ”¯æŒæ¡ä»¶åˆ†æ”¯ã€å¾ªç¯å’Œå›æº¯
- âœ… **æ¨¡å—åŒ–**: æ¯ä¸ªèŠ‚ç‚¹ç‹¬ç«‹å¼€å‘å’Œæµ‹è¯•
- âœ… **å¯æ¢å¤**: æ”¯æŒçŠ¶æ€æŒä¹…åŒ–å’Œæ–­ç‚¹æ¢å¤

## ğŸ—ï¸ æ ¸å¿ƒç»„ä»¶æ·±åº¦è§£æ

### 2.1 StateGraph - å›¾çš„æ„å»ºè€…

**ç»„ä»¶èŒè´£**ï¼š
- ğŸ¯ **å›¾ç»“æ„å®šä¹‰**: ç®¡ç†èŠ‚ç‚¹å’Œè¾¹çš„å…³ç³»
- ğŸ”„ **çŠ¶æ€ç®¡ç†**: ç»´æŠ¤å…¨å±€çŠ¶æ€çš„ä¸€è‡´æ€§
- ğŸš¦ **æ‰§è¡Œæ§åˆ¶**: æ§åˆ¶å·¥ä½œæµçš„æ‰§è¡Œé¡ºåºå’Œæ¡ä»¶

**åŸºç¡€ä½¿ç”¨æ¨¡å¼**ï¼š
```python
from langgraph.graph import StateGraph, END
from typing_extensions import TypedDict

# 1. å®šä¹‰çŠ¶æ€ç»“æ„
class AgentState(TypedDict):
    input: str
    chat_history: list
    intermediate_steps: list

# 2. åˆ›å»ºå›¾å®ä¾‹
workflow = StateGraph(AgentState)

# 3. æ·»åŠ èŠ‚ç‚¹
workflow.add_node("researcher", research_node)
workflow.add_node("writer", write_node)

# 4. å®šä¹‰è¾¹å…³ç³»
workflow.add_edge("researcher", "writer")
workflow.add_edge("writer", END)

# 5. è®¾ç½®å…¥å£ç‚¹
workflow.set_entry_point("researcher")
```

### 2.2 Node - æ‰§è¡Œçš„åŸºæœ¬å•å…ƒ

**èŠ‚ç‚¹ç±»å‹åˆ†ç±»**ï¼š

**1. å‡½æ•°èŠ‚ç‚¹** (æœ€å¸¸ç”¨)
```python
def research_node(state: AgentState):
    """ç ”ç©¶èŠ‚ç‚¹ - æ”¶é›†ä¿¡æ¯"""
    query = state["input"]
    # æ‰§è¡Œç ”ç©¶é€»è¾‘
    research_results = perform_research(query)
    
    # è¿”å›çŠ¶æ€æ›´æ–°
    return {
        "intermediate_steps": state["intermediate_steps"] + [
            {"action": "research", "result": research_results}
        ]
    }
```

**2. LLMèŠ‚ç‚¹** (AIæ¨ç†)
```python
def llm_node(state: AgentState):
    """LLMæ¨ç†èŠ‚ç‚¹"""
    prompt = create_prompt(state)
    response = llm.invoke(prompt)
    
    return {
        "chat_history": state["chat_history"] + [
            {"role": "assistant", "content": response.content}
        ]
    }
```

**3. å·¥å…·èŠ‚ç‚¹** (å¤–éƒ¨è°ƒç”¨)
```python
def tool_node(state: AgentState):
    """å·¥å…·è°ƒç”¨èŠ‚ç‚¹"""
    tool_call = state["intermediate_steps"][-1]
    result = execute_tool(tool_call["tool"], tool_call["input"])
    
    return {
        "intermediate_steps": state["intermediate_steps"] + [
            {"action": "tool_result", "result": result}
        ]
    }
```

### 2.3 State - çŠ¶æ€ç®¡ç†çš„æ ¸å¿ƒ

**çŠ¶æ€è®¾è®¡åŸåˆ™**ï¼š

**1. ç±»å‹å®‰å…¨è®¾è®¡**
```python
from typing_extensions import TypedDict, NotRequired
from typing import List, Dict, Any

class ComprehensiveState(TypedDict):
    # å¿…éœ€å­—æ®µ
    input: str
    output: str
    
    # å¯é€‰å­—æ®µ 
    chat_history: NotRequired[List[Dict[str, str]]]
    metadata: NotRequired[Dict[str, Any]]
    
    # æ§åˆ¶å­—æ®µ
    current_step: NotRequired[str]
    error_message: NotRequired[str]
```

**2. çŠ¶æ€æ›´æ–°æœºåˆ¶**
```python
# å¢é‡æ›´æ–° (æ¨è)
def node_function(state: ComprehensiveState):
    return {
        "chat_history": state.get("chat_history", []) + [new_message],
        "current_step": "processing"
    }

# å…¨é‡æ›´æ–° (è°¨æ…ä½¿ç”¨)
def full_update_node(state: ComprehensiveState):
    return {
        **state,
        "output": "å®Œæˆå¤„ç†",
        "current_step": "completed"
    }
```

## ğŸ’» ç¬¬ä¸€ä¸ªå®Œæ•´ç¤ºä¾‹

### 3.1 æ™ºèƒ½é—®ç­”ç³»ç»Ÿ

**ä¸šåŠ¡åœºæ™¯**: æ„å»ºä¸€ä¸ªå…·æœ‰ç ”ç©¶èƒ½åŠ›çš„AIåŠ©æ‰‹ï¼Œèƒ½å¤Ÿå…ˆæœç´¢ä¿¡æ¯å†ç”Ÿæˆå›ç­”ã€‚

**å®Œæ•´å®ç°**ï¼š

```python
from langgraph.graph import StateGraph, END
from typing_extensions import TypedDict, NotRequired
import json

# 1. çŠ¶æ€å®šä¹‰
class QAState(TypedDict):
    question: str
    research_query: NotRequired[str]
    search_results: NotRequired[list]
    final_answer: NotRequired[str]
    step_history: NotRequired[list]

# 2. èŠ‚ç‚¹å®ç°
def query_analysis_node(state: QAState):
    """åˆ†æé—®é¢˜ï¼Œç”Ÿæˆæœç´¢æŸ¥è¯¢"""
    question = state["question"]
    
    # ç®€å•çš„æŸ¥è¯¢æå–é€»è¾‘ (å®é™…åœºæ™¯ä¸­ä½¿ç”¨LLM)
    research_query = f"è¯¦ç»†è§£é‡Š {question}"
    
    return {
        "research_query": research_query,
        "step_history": state.get("step_history", []) + ["æŸ¥è¯¢åˆ†æå®Œæˆ"]
    }

def research_node(state: QAState):
    """æ‰§è¡Œä¿¡æ¯æœç´¢"""
    query = state["research_query"]
    
    # æ¨¡æ‹Ÿæœç´¢ç»“æœ
    mock_results = [
        {"title": "ç›¸å…³æ–‡æ¡£1", "content": f"å…³äº{query}çš„è¯¦ç»†ä¿¡æ¯..."},
        {"title": "ç›¸å…³æ–‡æ¡£2", "content": f"{query}çš„å®é™…åº”ç”¨æ¡ˆä¾‹..."}
    ]
    
    return {
        "search_results": mock_results,
        "step_history": state.get("step_history", []) + ["ä¿¡æ¯æœç´¢å®Œæˆ"]
    }

def answer_generation_node(state: QAState):
    """åŸºäºæœç´¢ç»“æœç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ"""
    question = state["question"]
    results = state["search_results"]
    
    # æ•´åˆä¿¡æ¯ç”Ÿæˆç­”æ¡ˆ (å®é™…åœºæ™¯ä¸­ä½¿ç”¨LLM)
    context = "\n".join([r["content"] for r in results])
    final_answer = f"åŸºäºæœç´¢ç»“æœï¼Œ{question}çš„ç­”æ¡ˆæ˜¯ï¼š\n{context[:200]}..."
    
    return {
        "final_answer": final_answer,
        "step_history": state.get("step_history", []) + ["ç­”æ¡ˆç”Ÿæˆå®Œæˆ"]
    }

# 3. æ„å»ºå·¥ä½œæµ
def create_qa_workflow():
    workflow = StateGraph(QAState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("analyze", query_analysis_node)
    workflow.add_node("research", research_node)  
    workflow.add_node("answer", answer_generation_node)
    
    # å®šä¹‰æ‰§è¡Œæµç¨‹
    workflow.set_entry_point("analyze")
    workflow.add_edge("analyze", "research")
    workflow.add_edge("research", "answer")
    workflow.add_edge("answer", END)
    
    return workflow.compile()

# 4. ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    app = create_qa_workflow()
    
    # æ‰§è¡ŒæŸ¥è¯¢
    result = app.invoke({
        "question": "ä»€ä¹ˆæ˜¯LangGraphï¼Ÿ"
    })
    
    print("=== æ‰§è¡Œç»“æœ ===")
    print(f"é—®é¢˜: {result['question']}")
    print(f"æœç´¢æŸ¥è¯¢: {result['research_query']}")
    print(f"æœ€ç»ˆç­”æ¡ˆ: {result['final_answer']}")
    print(f"æ‰§è¡Œå†å²: {result['step_history']}")
```

### 3.2 è¿è¡Œç»“æœåˆ†æ

**é¢„æœŸè¾“å‡º**ï¼š
```
=== æ‰§è¡Œç»“æœ ===
é—®é¢˜: ä»€ä¹ˆæ˜¯LangGraphï¼Ÿ
æœç´¢æŸ¥è¯¢: è¯¦ç»†è§£é‡Š ä»€ä¹ˆæ˜¯LangGraphï¼Ÿ
æœ€ç»ˆç­”æ¡ˆ: åŸºäºæœç´¢ç»“æœï¼Œä»€ä¹ˆæ˜¯LangGraphï¼Ÿçš„ç­”æ¡ˆæ˜¯ï¼š
å…³äºè¯¦ç»†è§£é‡Š ä»€ä¹ˆæ˜¯LangGraphï¼Ÿçš„è¯¦ç»†ä¿¡æ¯...
è¯¦ç»†è§£é‡Š ä»€ä¹ˆæ˜¯LangGraphï¼Ÿçš„å®é™…åº”ç”¨æ¡ˆä¾‹...
æ‰§è¡Œå†å²: ['æŸ¥è¯¢åˆ†æå®Œæˆ', 'ä¿¡æ¯æœç´¢å®Œæˆ', 'ç­”æ¡ˆç”Ÿæˆå®Œæˆ']
```

**å…³é”®è§‚å¯Ÿç‚¹**ï¼š
- âœ… **çŠ¶æ€ä¼ é€’**: æ¯ä¸ªèŠ‚ç‚¹éƒ½èƒ½è®¿é—®å‰é¢èŠ‚ç‚¹çš„å¤„ç†ç»“æœ
- âœ… **å¢é‡æ›´æ–°**: `step_history`é€æ­¥ç´¯ç§¯æ‰§è¡Œè®°å½•
- âœ… **æ¨¡å—åŒ–**: æ¯ä¸ªèŠ‚ç‚¹èŒè´£å•ä¸€ï¼Œæ˜“äºæµ‹è¯•å’Œç»´æŠ¤
- âœ… **å¯æ‰©å±•**: å¯ä»¥è½»æ¾æ·»åŠ æ–°çš„å¤„ç†èŠ‚ç‚¹

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µå¯¹æ¯”

### 4.1 LangGraph vs ä¼ ç»Ÿé“¾å¼ç»“æ„

| ç‰¹æ€§ç»´åº¦ | ä¼ ç»ŸLangChainé“¾ | LangGraphå›¾ç»“æ„ |
|---------|----------------|----------------|
| **çŠ¶æ€ç®¡ç†** | æ¯ä¸ªç»„ä»¶ç‹¬ç«‹çŠ¶æ€ | å…¨å±€å…±äº«çŠ¶æ€ |
| **æ‰§è¡Œæ¨¡å¼** | ä¸¥æ ¼çº¿æ€§æ‰§è¡Œ | çµæ´»çš„å›¾æ‰§è¡Œ |
| **é”™è¯¯å¤„ç†** | é“¾å¼ä¼ æ’­ï¼Œéš¾ä»¥æ¢å¤ | èŠ‚ç‚¹çº§å¤„ç†ï¼Œæ”¯æŒé‡è¯• |
| **æ‰©å±•æ€§** | éœ€é‡æ„æ•´ä¸ªé“¾ | å¢åŠ èŠ‚ç‚¹å’Œè¾¹å³å¯ |
| **è°ƒè¯•æ€§** | é»‘ç›’å¼æ‰§è¡Œ | çŠ¶æ€å¯è§‚æµ‹ï¼Œæ­¥éª¤å¯è¿½è¸ª |
| **å¤ç”¨æ€§** | ç»„ä»¶è€¦åˆåº¦é«˜ | èŠ‚ç‚¹ç‹¬ç«‹ï¼Œé«˜åº¦å¤ç”¨ |

### 4.2 è®¾è®¡å“²å­¦å·®å¼‚

**LangChainé“¾å¼å“²å­¦**ï¼š
```python
# çº¿æ€§æ€ç»´ï¼šè¾“å…¥ â†’ å¤„ç† â†’ è¾“å‡º
chain = prompt | llm | parser | validator
result = chain.invoke(input)
```

**LangGraphå›¾å¼å“²å­¦**ï¼š
```python
# å›¾çŠ¶æ€æ€ç»´ï¼šçŠ¶æ€ â†’ èŠ‚ç‚¹è½¬æ¢ â†’ æ–°çŠ¶æ€
graph = StateGraph(State)
graph.add_node("process", transform_state)
graph.add_edge("process", conditional_next)
app = graph.compile()
```

## ğŸ“‹ æœ€ä½³å®è·µæŒ‡å—

### 5.1 çŠ¶æ€è®¾è®¡æœ€ä½³å®è·µ

**1. ç±»å‹å®‰å…¨ä¼˜å…ˆ**
```python
# âœ… æ¨èï¼šä½¿ç”¨TypedDictç¡®ä¿ç±»å‹å®‰å…¨
class MyState(TypedDict):
    required_field: str
    optional_field: NotRequired[int]

# âŒ é¿å…ï¼šä½¿ç”¨æ™®é€šå­—å…¸
state = {"field1": "value1", "field2": 42}
```

**2. æœ€å°åŒ–çŠ¶æ€åŸåˆ™**
```python
# âœ… æ¨èï¼šåªä¿ç•™å¿…è¦çš„çŠ¶æ€
class MinimalState(TypedDict):
    user_input: str
    processed_result: str
    
# âŒ é¿å…ï¼šçŠ¶æ€è‡ƒè‚¿
class BloatedState(TypedDict):
    everything_you_can_imagine: Any
```

**3. çŠ¶æ€ç‰ˆæœ¬æ§åˆ¶**
```python
# âœ… æ¨èï¼šçŠ¶æ€å˜åŒ–å¯è¿½è¸ª
class VersionedState(TypedDict):
    data: str
    version: int
    last_modified_by: str
```

### 5.2 èŠ‚ç‚¹è®¾è®¡æœ€ä½³å®è·µ

**1. å•ä¸€èŒè´£åŸåˆ™**
```python
# âœ… æ¨èï¼šæ¯ä¸ªèŠ‚ç‚¹èŒè´£å•ä¸€
def validate_input(state): # åªè´Ÿè´£éªŒè¯
    pass

def process_data(state):   # åªè´Ÿè´£å¤„ç†
    pass

# âŒ é¿å…ï¼šèŠ‚ç‚¹èŒè´£è¿‡é‡
def validate_and_process_and_save(state):
    pass
```

**2. å¹‚ç­‰æ€§è®¾è®¡**
```python
# âœ… æ¨èï¼šå¹‚ç­‰æ“ä½œï¼Œå¯é‡å¤æ‰§è¡Œ
def idempotent_node(state):
    if not state.get("processed", False):
        # æ‰§è¡Œå¤„ç†é€»è¾‘
        return {"processed": True, "result": "xxx"}
    return {}  # å·²å¤„ç†ï¼Œä¸é‡å¤æ‰§è¡Œ
```

## ğŸ”® è¿›é˜¶é¢„å‘Š

**L2å±‚é¢„å‘Š - çŠ¶æ€ç®¡ç†ä¸æ¡ä»¶è·¯ç”±**ï¼š
- ğŸ¯ **æ¡ä»¶è¾¹è®¾è®¡**: æ ¹æ®çŠ¶æ€åŠ¨æ€é€‰æ‹©ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
- ğŸ”„ **å¾ªç¯æ§åˆ¶**: å®ç°è¿­ä»£ä¼˜åŒ–å’Œé‡è¯•æœºåˆ¶
- ğŸ§  **æ™ºèƒ½è·¯ç”±**: æ„å»ºå…·æœ‰å†³ç­–èƒ½åŠ›çš„å·¥ä½œæµ
- âš¡ **æ€§èƒ½ä¼˜åŒ–**: çŠ¶æ€æ›´æ–°å’Œå†…å­˜ç®¡ç†æŠ€å·§

## ğŸ“ ç»ƒä¹ ä¸æ€è€ƒ

**åŸºç¡€ç»ƒä¹ **ï¼š
1. ä¿®æ”¹ç¤ºä¾‹ä¸­çš„QAç³»ç»Ÿï¼Œæ·»åŠ ä¸€ä¸ª"ç»“æœéªŒè¯"èŠ‚ç‚¹
2. è®¾è®¡ä¸€ä¸ªç®€å•çš„å†…å®¹ç”Ÿæˆå·¥ä½œæµï¼šè¾“å…¥ä¸»é¢˜ â†’ å¤§çº²ç”Ÿæˆ â†’ å†…å®¹å†™ä½œ â†’ è´¨é‡æ£€æŸ¥
3. å®ç°ä¸€ä¸ªå¤šæ­¥éª¤æ•°æ®å¤„ç†æµç¨‹ï¼Œä½“éªŒçŠ¶æ€åœ¨èŠ‚ç‚¹é—´çš„ä¼ é€’

**æ€è€ƒé¢˜**ï¼š
1. ä»€ä¹ˆåœºæ™¯ä¸‹åº”è¯¥ä½¿ç”¨LangGraphè€Œä¸æ˜¯ä¼ ç»Ÿçš„LangChainé“¾ï¼Ÿ
2. å¦‚ä½•è®¾è®¡çŠ¶æ€ç»“æ„æ‰èƒ½æœ€å¥½åœ°æ”¯æŒæœªæ¥çš„æ‰©å±•éœ€æ±‚ï¼Ÿ
3. èŠ‚ç‚¹çš„ç²’åº¦åº”è¯¥å¦‚ä½•æŠŠæ¡ï¼Ÿå¤ªç»†å’Œå¤ªç²—å„æœ‰ä»€ä¹ˆé—®é¢˜ï¼Ÿ

---

**ğŸ¯ å­¦ä¹ æ£€éªŒ**: å®Œæˆæœ¬ç« å­¦ä¹ åï¼Œä½ åº”è¯¥èƒ½å¤Ÿç‹¬ç«‹æ„å»ºä¸€ä¸ªå…·æœ‰3-5ä¸ªèŠ‚ç‚¹çš„ç®€å•å›¾å·¥ä½œæµï¼Œå¹¶ç†è§£çŠ¶æ€åœ¨èŠ‚ç‚¹é—´çš„ä¼ é€’æœºåˆ¶ã€‚

**ğŸ‘‰ ä¸‹ä¸€æ­¥**: [L2: çŠ¶æ€ç®¡ç†ä¸æ¡ä»¶è·¯ç”±](./02-çŠ¶æ€ç®¡ç†ä¸æ¡ä»¶è·¯ç”±.md) - è®©ä½ çš„å·¥ä½œæµå…·å¤‡å†³ç­–èƒ½åŠ›ï¼